### **1. Use Indexes Wisely**

Indexes speed up searches by avoiding full table scans.

**Types:**

* **Primary Index:** Automatically created on primary key
* **Secondary Index:** Created manually on non-primary key columns
* **Clustered Index:** Defines row order (only one per table)
* **Non-Clustered Index:** Stores pointers to data, can have multiple

**Example:**

```sql
CREATE INDEX idx_orders_customer_id ON orders(customer_id);
SELECT * FROM orders WHERE customer_id = 123;
```

**Best Practices:**

* Index columns in `WHERE`, `JOIN`, `ORDER BY`.
* Avoid over-indexing (slows down writes).
* Monitor and tune index usage regularly.

---

### **2. Avoid `SELECT *`**

Fetch only the required columns.
This reduces I/O load and improves query readability.

**Example:**

```sql
SELECT product_id, product_name, price FROM products;
```

---

### **3. Limit Rows with `WHERE` and `LIMIT`**

Avoid fetching unnecessary rows.
Filter precisely and restrict output.

**Example:**

```sql
SELECT name FROM customers
WHERE country = 'USA'
ORDER BY signup_date DESC
LIMIT 50;
```

---

### **4. Write Efficient `WHERE` Clauses**

Avoid functions or math operations on columns, as they disable index usage.

**Bad:**

```sql
SELECT * FROM employees WHERE YEAR(joining_date) = 2022;
```

**Optimized:**

```sql
SELECT * FROM employees
WHERE joining_date >= '2022-01-01' AND joining_date < '2023-01-01';
```

---

### **5. Avoid Functions on Indexed Columns**

Functions disable indexes and force full table scans.

**Example:**

```sql
SELECT * FROM users WHERE email = 'john@gmail.com';
```

---

### **6. Use Joins Smartly**

Join only necessary tables and filter data before joining.
Prefer `INNER JOIN` when unmatched records are not needed.

**Example:**

```sql
SELECT u.name, o.amount
FROM users u
JOIN orders o ON u.user_id = o.user_id
WHERE o.amount > 100;
```

---

### **7. Avoid N+1 Query Problems**

Fetch related data in one query using JOINs instead of multiple queries in loops.

---

### **8. Use `EXISTS` Instead of `IN` (for Subqueries)**

`EXISTS` stops searching after the first match, making it more efficient.

**Example:**

```sql
SELECT name FROM customers
WHERE EXISTS (
  SELECT 1 FROM orders WHERE orders.customer_id = customers.customer_id
);
```

---

### **9. Avoid Wildcards at the Start of `LIKE`**

Using `%` at the beginning of a `LIKE` pattern disables index usage.

**Example:**

```sql
SELECT * FROM users WHERE name LIKE 'john%';
```

---

### **10. Consider Denormalization**

For read-heavy workloads, store some redundant data to reduce complex joins.

---

### **11. Use Execution Plans**

Use `EXPLAIN` or `EXPLAIN ANALYZE` to understand query performance.

**Example:**

```sql
EXPLAIN SELECT * FROM orders WHERE user_id = 42;
```

---

### **12. Use `UNION ALL` Instead of `UNION`**

`UNION` removes duplicates, adding sorting overhead.
Use `UNION ALL` when duplicates are acceptable.

---

### **13. Avoid `SELECT` Inside Loops**

Avoid multiple queries inside loops in applications; batch queries instead.

**Example:**

```sql
SELECT id, name FROM users WHERE id IN (1, 2, 3, 4);
```

---

### **14. Partition Large Tables**

Split large tables into partitions (e.g., by year or region) for faster scans and better index efficiency.

---

### **15. Optimize `ORDER BY` and `GROUP BY`**

Sorting and grouping are expensive.
Limit sorted rows and ensure indexes match the sort columns.

**Example:**

```sql
SELECT order_id, amount FROM orders
WHERE created_at >= '2023-01-01'
ORDER BY created_at;
```

---

### **Summary**

| Goal                | Technique                              |
| ------------------- | -------------------------------------- |
| Faster lookups      | Use indexes wisely                     |
| Reduce load         | Avoid `SELECT *` and unnecessary joins |
| Efficient filtering | Write index-friendly `WHERE` clauses   |
| Scalable reads      | Use partitioning and denormalization   |
| Debug performance   | Use `EXPLAIN` plans                    |

---

### **Key Takeaway**

“Write SQL as if you’ll run it on a billion rows tomorrow.”
Optimize for scalability and long-term efficiency.
