# **Day 11: Data Anomalies and Database Normalization**


## **2. Introduction to Database Normalization**

### **Definition**

**Database Normalization** is the process of organizing the data in a database to **minimize redundancy** and **maintain data integrity**.
It ensures that data is **consistent**, **efficiently stored**, and **easily maintainable** by dividing large, unstructured tables into smaller, related ones.

In simpler terms, normalization structures data so that each fact is stored **only once**.

---

### **Why Normalization is Needed**

Normalization aims to **remove anomalies** and **improve data quality**.
Without normalization, databases can suffer from:

1. **Insertion Anomalies:** Unable to insert data due to missing required fields.
   Example: Cannot add a customer’s order if the customer record doesn’t exist.
2. **Deletion Anomalies:** Deleting one record unintentionally deletes related information.
   Example: Deleting a customer also removes their order history.
3. **Updation Anomalies:** Updating data in one place but not others causes inconsistency.
   Example: Updating an employee’s department name in only one of multiple records.

Thus, normalization is applied to create a **reliable**, **consistent**, and **redundancy-free** database structure.

---

### **How Normalization Works**

Normalization splits a large table into **smaller, interlinked tables**.
Each smaller table contains **atomic (indivisible)** information and is linked using **keys**.

* **Before Normalization:** Data stored in one big table → redundant and inconsistent.
* **After Normalization:** Data divided into logical tables → consistent, minimal redundancy, and anomaly-free.

---

### **Features of Database Normalization**

| **Feature**                    | **Explanation**                                                                               |
| ------------------------------ | --------------------------------------------------------------------------------------------- |
| **Elimination of Redundancy**  | Removes duplicate data from multiple locations, reducing storage and inconsistency.           |
| **Ensuring Consistency**       | Keeps data accurate and uniform by maintaining single sources of truth.                       |
| **Simplified Data Management** | Data is organized into simpler, smaller tables that are easier to maintain and query.         |
| **Improved Database Design**   | Provides a structured and flexible design adaptable to future changes.                        |
| **Avoids Update Anomalies**    | Ensures updates are made in one place, maintaining consistency across the system.             |
| **Standardization**            | Organizes data in a consistent format across the database, improving quality and reliability. |

---

### **Normal Forms in DBMS**

Normalization follows a series of levels called **Normal Forms (NFs)**.
Each normal form builds upon the previous one, progressively improving the structure of the database.

| **Normal Form**                   | **Condition**                                                                                  | **Purpose**                                                    |
| --------------------------------- | ---------------------------------------------------------------------------------------------- | -------------------------------------------------------------- |
| **First Normal Form (1NF)**       | All attributes contain **atomic (indivisible)** values.                                        | Removes **repeating groups** and **multivalued attributes**.   |
| **Second Normal Form (2NF)**      | Must be in **1NF**, and every non-key attribute is **fully dependent** on the **primary key**. | Removes **partial dependencies**.                              |
| **Third Normal Form (3NF)**       | Must be in **2NF**, and there are **no transitive dependencies**.                              | Removes **indirect dependencies**.                             |
| **Boyce-Codd Normal Form (BCNF)** | Must be in **3NF**, and for every functional dependency **X → Y**, X must be a **superkey**.   | A stricter version of **3NF**, ensuring strong key dependency. |
| **Fourth Normal Form (4NF)**      | Must be in **BCNF**, and there are **no multi-valued dependencies**.                           | Eliminates multi-valued dependencies.                          |
| **Fifth Normal Form (5NF)**       | Must be in **4NF**, and the table cannot be further **non-loss decomposed**.                   | Removes **join dependencies** for complete decomposition.      |

---

### **Advantages of Normalization**

| **Advantage**              | **Explanation**                                                              |
| -------------------------- | ---------------------------------------------------------------------------- |
| **Removes Redundancy**     | Each piece of data is stored only once.                                      |
| **Ensures Data Integrity** | Prevents anomalies and maintains consistency.                                |
| **Simplifies Updates**     | Data modifications occur in one location only.                               |
| **Efficient Querying**     | Organized data supports flexible and accurate queries.                       |
| **Supports Integration**   | Consistent data structure improves interoperability with other applications. |

---

### **Disadvantages of Normalization**

| **Disadvantage**         | **Explanation**                                                           |
| ------------------------ | ------------------------------------------------------------------------- |
| **Performance Overhead** | Increased number of joins can slow down queries.                          |
| **Complex Queries**      | Retrieving related data may require multiple table joins.                 |
| **Design Complexity**    | Requires expert understanding of relationships and dependencies.          |
| **Loss of Context**      | Splitting data into multiple tables can obscure its logical relationship. |

---

### **Summary**

| **Aspect**    | **Description**                                                   |
| ------------- | ----------------------------------------------------------------- |
| **Goal**      | Reduce redundancy, maintain consistency, and eliminate anomalies. |
| **Method**    | Divide large tables into smaller related tables using keys.       |
| **Result**    | Efficient, reliable, and flexible database design.                |
| **Trade-off** | Slight increase in query complexity due to joins.                 |

---

### **Key Takeaway**

Normalization is **essential for efficient database design**.
It balances **data integrity** and **performance**, ensuring that the database is **consistent**, **structured**, and **scalable** for long-term use.

---