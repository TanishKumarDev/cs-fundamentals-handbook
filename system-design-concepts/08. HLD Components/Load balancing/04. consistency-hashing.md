# Consistent Hashing in System Design - Complete Guide

Consistent hashing is a distributed hashing technique that addresses the limitations of traditional hashing by minimizing data remapping when servers are added or removed. It uses a virtual ring to map keys and servers, ensuring scalability, load balancing, and fault tolerance. This guide covers the problem with traditional hashing, the concept of consistent hashing, its mechanism, virtual nodes, implementation, benefits, and real-world applications.

## The Basic Problem: Why We Need Hashing

In a system with a large dataset, such as a school library with thousands of books, managing data with a single server (librarian) becomes overwhelming. The solution is to distribute data across multiple servers (librarians). Hashing determines which server handles each data item (book), but traditional hashing has significant drawbacks when scaling.

**Analogy**: A library with one librarian struggles with 10,000 books. Hiring more librarians and dividing books among them requires an efficient method to assign books to librarians without constant reorganization.

## Traditional Hashing (The Naive Way)

Traditional hashing, often using a modulus method, assigns data to servers based on a simple hash function.

**Modulus Method**:
```javascript
// Which shelf should the book go on?
function findShelf(bookId, totalShelves) {
    return bookId % totalShelves;  // Simple division remainder
}
```

**Example with 3 Shelves**:
| Book ID | Calculation | Shelf   |
|---------|-------------|---------|
| 1       | 1 % 3 = 1   | Shelf 1 |
| 2       | 2 % 3 = 2   | Shelf 2 |
| 3       | 3 % 3 = 0   | Shelf 0 |
| 4       | 4 % 3 = 1   | Shelf 1 |

**Problem with Traditional Hashing**:
- **Scaling Issue**: Adding a new shelf (server) changes the modulus (e.g., from 3 to 4), requiring most data to be reassigned.
  - Example: With 4 shelves, Book 3 moves from Shelf 0 (`3 % 3 = 0`) to Shelf 3 (`3 % 4 = 3`), affecting ~80% of books.
- **Consequences**: High rehashing overhead, system instability, and downtime during scaling.

## Consistent Hashing (The Smart Way)

Consistent hashing solves these issues by using a virtual ring structure to map keys and servers, minimizing data movement during scaling.

**Core Concept**:
- A circular ring (Ferris wheel) represents hash values (e.g., 0 to 359).
- Servers and keys are placed on the ring using a hash function.
- Each key is assigned to the next server clockwise, ensuring minimal disruption when servers are added or removed.

**Analogy**: A Ferris wheel with numbered seats (0 to 11) where librarians (servers) and books (keys) are placed. Books are assigned to the next librarian clockwise, and adding a new librarian only affects nearby books.

**Mechanism**:
1. **Place Servers on the Ring**:
   - Hash server IDs to assign positions (e.g., Server A at 2, B at 5, C at 9).
   - Example:
     ```
     Wheel: 0 1 2 3 4 5 6 7 8 9 10 11
     Servers:   A       B         C
                2       5         9
     ```

2. **Place Keys on the Ring**:
   - Hash keys to positions (e.g., Book 1 at 1, Book 2 at 4, Book 3 at 7, Book 4 at 10).
   - Assign each key to the next clockwise server.
   - Example:
     | Book   | Position | Goes To        |
     |--------|----------|----------------|
     | Book 1 | 1        | Server B (5)   |
     | Book 2 | 4        | Server B (5)   |
     | Book 3 | 7        | Server C (9)   |
     | Book 4 | 10       | Server A (2)   |

3. **Add a New Server**:
   - Adding Server D at position 7 only affects keys between the previous server (B at 5) and D.
   - Example:
     ```
     Before: 0 1 2(A) 3 4 5(B) 6 7 8 9(C) 10 11
     After:  0 1 2(A) 3 4 5(B) 6 7(D) 8 9(C) 10 11
     ```
     - Book 3 (at 7) moves from Server C to Server D; others remain unchanged.

## Advanced: Virtual Nodes

**Problem**: Uneven distribution occurs if servers cluster on the ring (e.g., all in one half, causing one server to handle most keys).

**Solution**: Assign multiple virtual nodes (replicas) to each physical server to spread positions evenly.
- Example:
  ```
  Real Server A: Positions 1, 5, 9
  Real Server B: Positions 3, 7, 11
  Real Server C: Positions 2, 6, 10
  ```
- Benefit: Improves load balancing by distributing keys more uniformly.

## User Request Flow: Step-by-Step Walkthrough

### Phase 1: Setting Up the System
1. **Deploy Servers**:
   ```javascript
   const servers = [
       { id: 'server-A', ip: '192.168.1.10' },
       { id: 'server-B', ip: '192.168.1.11' },
       { id: 'server-C', ip: '192.168.1.12' }
   ];
   ```

2. **Create Hash Ring and Place Servers**:
   ```javascript
   function hash(key) {
       let hash = 0;
       for (let i = 0; i < key.length; i++) {
           hash = (hash << 5) - hash + key.charCodeAt(i);
           hash |= 0;
       }
       return Math.abs(hash) % 360; // 0-359 degrees
   }

   const ring = new Map();
   ring.set(hash('server-A'), 'server-A'); // e.g., 45
   ring.set(hash('server-B'), 'server-B'); // e.g., 150
   ring.set(hash('server-C'), 'server-C'); // e.g., 270
   ```

   **Ring Visualization**:
   ```
   0°
   |  45°(A)   90°
   |     ↖       ↗
   180° ←-----→ 0°
   |     ↙       ↘
   |  150°(B)  270°(C)
   ```

### Phase 2: User Stores Data
- User "John" (ID: "john123") stores profile data.
  ```javascript
  const johnPosition = hash('john123'); // e.g., 200
  function findServer(userPosition) {
      const positions = Array.from(ring.keys()).sort((a, b) => a - b);
      for (let serverPos of positions) {
          if (serverPos >= userPosition) {
              return ring.get(serverPos);
          }
      }
      return ring.get(positions[0]); // Wrap around
  }
  const targetServer = findServer(200); // Returns 'server-C' (270)
  ```
  **Result**: John’s data is stored on Server-C.

### Phase 3: User Requests Data
- John retrieves profile data.
  ```javascript
  const johnPosition = hash('john123'); // Still 200 (deterministic)
  const targetServer = findServer(200); // Still 'server-C'
  routeRequestToServer('server-C', 'get_profile', 'john123');
  ```
  **Result**: Request routed to Server-C, which returns John’s data.

### Phase 4: Adding a New Server
- Add Server-D at position 220.
  ```javascript
  ring.set(hash('server-D'), 'server-D'); // e.g., 220
  ```
  **New Ring**:
  ```
  0°---45°(A)---150°(B)---200°(john)---220°(D)---270°(C)
  ```
  **Changes**:
  - John’s request (`john123` at 200) now maps to Server-D (220) instead of Server-C.
  - Only keys between Server-B (150) and Server-D (220) are remapped.

## Complete Implementation

```javascript
class ConsistentHashing {
    constructor() {
        this.ring = new Map();
        this.sortedPositions = [];
    }
    
    addServer(serverId) {
        const position = this.hash(serverId);
        this.ring.set(position, serverId);
        this.updateSortedPositions();
        console.log(`Added ${serverId} at position ${position}`);
    }
    
    findServerForKey(key) {
        const position = this.hash(key);
        for (let serverPos of this.sortedPositions) {
            if (serverPos >= position) {
                const server = this.ring.get(serverPos);
                console.log(`Key "${key}" (pos:${position}) → ${server} (pos:${serverPos})`);
                return server;
            }
        }
        const server = this.ring.get(this.sortedPositions[0]);
        console.log(`Key "${key}" (pos:${position}) → ${server} (wrap around)`);
        return server;
    }
    
    hash(key) {
        let hash = 0;
        for (let i = 0; i < key.length; i++) {
            hash = (hash << 5) - hash + key.charCodeAt(i);
            hash |= 0;
        }
        return Math.abs(hash) % 360;
    }
    
    updateSortedPositions() {
        this.sortedPositions = Array.from(this.ring.keys()).sort((a, b) => a - b);
    }
}

// Example Usage
const ch = new ConsistentHashing();
ch.addServer('server-A');  // Position: 45
ch.addServer('server-B');  // Position: 150
ch.addServer('server-C');  // Position: 270

console.log('\n--- User Requests ---');
ch.findServerForKey('john123');  // → server-C
ch.findServerForKey('alice456'); // → server-A
ch.findServerForKey('bob789');   // → server-B

console.log('\n--- Adding Server-D ---');
ch.addServer('server-D');  // Position: 220

console.log('\n--- Same User Requests ---');
ch.findServerForKey('john123');  // → server-D
ch.findServerForKey('alice456'); // → server-A
ch.findServerForKey('bob789');   // → server-B
```

**Output**:
```
Added server-A at position 45
Added server-B at position 150
Added server-C at position 270

--- User Requests ---
Key "john123" (pos:200) → server-C (pos:270)
Key "alice456" (pos:30) → server-A (pos:45)
Key "bob789" (pos:100) → server-B (pos:150)

--- Adding Server-D ---
Added server-D at position 220

--- Same User Requests ---
Key "john123" (pos:200) → server-D (pos:220)
Key "alice456" (pos:30) → server-A (pos:45)
Key "bob789" (pos:100) → server-B (pos:150)
```

## Benefits of Consistent Hashing

| **Traditional Hashing**         | **Consistent Hashing**           |
|---------------------------------|----------------------------------|
| 80% data moves when scaling     | Only 10-20% data moves          |
| All calculations change         | Most mappings remain unchanged  |
| Complex scaling                 | Easy scaling                    |
| Hotspots common                 | Even distribution with virtual nodes |

**Key Benefits**:
1. **Minimal Data Movement**: Only keys in the affected range (e.g., 10-20%) are remapped when adding/removing servers.
2. **Deterministic Mapping**: Same key always maps to the same position, ensuring consistency.
3. **Scalability**: Handles dynamic server changes with minimal disruption.
4. **Load Balancing**: Virtual nodes prevent hotspots and ensure even distribution.

## Real-World Applications

Consistent hashing is used in systems requiring scalable data distribution:
1. **Netflix**: Maps movie data to servers for streaming.
2. **Google**: Distributes search data across database nodes.
3. **Amazon**: Assigns product data to warehouse servers.
4. **Uber**: Tracks ride data across servers.
5. **Caching Systems**: Distributes cache keys in systems like Memcached or Redis.

## Key Points to Remember

1. **Deterministic Hashing**: Same hash function ensures consistent key positions.
2. **Clockwise Search**: Keys are assigned to the next server clockwise.
3. **Minimal Disruption**: Adding/removing servers affects only nearby keys.
4. **Virtual Nodes**: Improve load balancing by spreading server positions.
5. **Scalability**: Enables efficient scaling in distributed systems.

## Best Practices for Consistent Hashing

1. **Use a Robust Hash Function**:
   - Ensure uniform distribution (e.g., replace simple hash with MD5 or SHA-1).
   - Example: Use SHA-256 for better key spread.

2. **Implement Virtual Nodes**:
   - Add multiple positions per server to avoid hotspots.
   - Example: Assign 3 virtual nodes per physical server.

3. **Optimize Load Balancing**:
   - Monitor key distribution and rebalance if uneven.
   - Example: Redistribute keys if one server handles 50% more than others.

4. **Handle Failures**:
   - Replicate keys across nodes for fault tolerance.
   - Example: Store keys on the next server for redundancy.

5. **Minimize Overhead**:
   - Use efficient data structures (e.g., sorted arrays) for lookups.
   - Example: Store positions in a sorted array for O(log n) searches.

## Summary

Consistent hashing is a distributed hashing technique that minimizes data movement during scaling, ensuring scalability, load balancing, and fault tolerance.

- **Core Concept**: Uses a virtual ring to map keys and servers, assigning keys to the next clockwise server.
- **Problem Solved**: Addresses traditional hashing’s issues (e.g., 80% data remapping, uneven distribution).
- **Mechanism**: Hash function, ring setup, key mapping, virtual nodes, and minimal remapping during server changes.
- **Benefits**: Minimal data movement (10-20%), deterministic mapping, easy scaling, even distribution.
- **Applications**: Distributed databases (e.g., Netflix, Google), caching systems (e.g., Memcached), load balancers, and ride-sharing systems (e.g., Uber).
- **Caching Context**: Used in caching systems to distribute cache keys, as noted in real-world applications.

**When to Use Consistent Hashing**:
- Distributed systems with dynamic server changes.
- Applications requiring load balancing and fault tolerance (e.g., databases, CDNs).
- Systems needing minimal disruption during scaling.

**When to Avoid Consistent Hashing**:
- Small-scale systems with static servers where simple hashing is sufficient.
- Applications where hash function overhead outweighs benefits.
- Systems not requiring dynamic scaling or fault tolerance.

Consistent hashing is a cornerstone of scalable distributed systems, enabling companies like Google, Amazon, and Netflix to manage large-scale data efficiently.

---
